{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Technologies - Lab 1\n",
    "## Data Handling and Visualisation Fundamentals\n",
    "\n",
    "**Objectives:**\n",
    "1. Learn to load and manipulate data with pandas\n",
    "2. Visualise data with matplotlib\n",
    "3. Work with images as numpy arrays\n",
    "4. Get familiar with basic scikit-learn workflows\n",
    "\n",
    "**Prerequisites:** Basic Python, numpy knowledge\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. NumPy refresher\n",
    "\n",
    "NumPy arrays are the foundation of scientific Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "print(a, a.shape, a.dtype)\n",
    "b = np.array([[1,2,3,4],[1,2,3,4]])\n",
    "print(b, b.shape, b.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.ones([3,3])\n",
    "print(c)\n",
    "d = np.arange(1,5)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Student Task\n",
    "\n",
    "Create a 3×4 NumPy array containing the values 0–11.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: create array\n",
    "# TODO: print array and shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Pandas\n",
    "\n",
    "Pandas is the standard library for data manipulation in Python. It provides two main data structures:\n",
    "- **Series**: 1D labelled array\n",
    "- **DataFrame**: 2D labelled data structure (like a spreadsheet)\n",
    "\n",
    "Let's start by importing the libraries we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Set display options for better output\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Pandas introduction\n",
    "\n",
    "Pandas provides labelled, tabular data structures.\n",
    "\n",
    "Before continuing, skim:\n",
    "https://pandas.pydata.org/docs/user_guide/10min.html\n",
    "\n",
    "One of the restrictions of numpy arrays is that everything must be of the same data type, Pandas does not have this issue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"Diana\"],\n",
    "    \"age\": [21, 23, 22, 24],\n",
    "    \"grade\": [68, 75, 82, 90]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select an individual column using df[\"name\"], this will return a series\n",
    "\n",
    "If we want to convert this to a numpy array use .values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"name\"])\n",
    "print(\"now as array:\")\n",
    "print(df[\"name\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Student Task\n",
    "\n",
    "- Select the `age` column  \n",
    "- Select `name` and `grade` together  \n",
    "- Filter rows where `grade >= 75`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## todo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(df[\"grade\"])\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Grade\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Student Task\n",
    "\n",
    "Create a bar chart of names vs grades.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Creating Sample Data\n",
    "\n",
    "First, let's create some sample CSV and JSON files to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample CSV file - Student Grades\n",
    "student_data = {\n",
    "    'student_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', \n",
    "             'Frank', 'Grace', 'Henry', 'Iris', 'Jack'],\n",
    "    'age': [20, 22, 21, 23, 20, 22, 21, 24, 20, 23],\n",
    "    'math_score': [85, 72, 90, 88, 76, 95, 82, 79, 91, 84],\n",
    "    'science_score': [78, 85, 88, 92, 81, 89, 87, 75, 94, 80],\n",
    "    'attendance': [95, 87, 92, 98, 85, 97, 90, 82, 96, 88]\n",
    "}\n",
    "\n",
    "df_students = pd.DataFrame(student_data)\n",
    "df_students.to_csv('students.csv', index=False)\n",
    "\n",
    "print(\"Created students.csv\")\n",
    "print(df_students.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample JSON file - Weather Data\n",
    "weather_data = {\n",
    "    'city': ['Limerick', 'Galway', 'Dublin', 'Cork', 'Belfast'],\n",
    "    'temperature': [12.5, 11.8, 13.2, 13.8, 10.9],\n",
    "    'humidity': [82, 85, 78, 80, 88],\n",
    "    'wind_speed': [15.2, 18.5, 12.3, 14.1, 20.3],\n",
    "    'rainfall_mm': [2.3, 3.1, 1.8, 2.0, 3.8]\n",
    "}\n",
    "\n",
    "df_weather = pd.DataFrame(weather_data)\n",
    "df_weather.to_json('weather.json', orient='records', indent=2)\n",
    "\n",
    "print(\"Created weather.json\")\n",
    "print(df_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Loading Data\n",
    "\n",
    "Now let's load these files and explore them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV file\n",
    "students_df = pd.read_csv('students.csv')\n",
    "\n",
    "print(\"First few rows:\")\n",
    "print(students_df.head())\n",
    "\n",
    "print(\"\\nDataFrame info:\")\n",
    "print(students_df.info())\n",
    "\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(students_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON file\n",
    "weather_df = pd.read_json('weather.json')\n",
    "\n",
    "print(\"Weather DataFrame:\")\n",
    "print(weather_df)\n",
    "\n",
    "print(\"\\nColumn data types:\")\n",
    "print(weather_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Wrangling\n",
    "\n",
    "**Task 1:** Let's perform some common data manipulation tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1a: Calculate average score for each student\n",
    "students_df['average_score'] = (students_df['math_score'] + \n",
    "                                 students_df['science_score']) / 2\n",
    "\n",
    "print(\"Students with average scores:\")\n",
    "print(students_df[['name', 'math_score', 'science_score', 'average_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1b: Filter students with average > 85\n",
    "high_performers = students_df[students_df['average_score'] > 85]\n",
    "\n",
    "print(f\"\\nHigh performers (avg > 85): {len(high_performers)} students\")\n",
    "print(high_performers[['name', 'average_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1c: Group by age and calculate mean scores\n",
    "age_groups = students_df.groupby('age').agg({\n",
    "    'math_score': 'mean',\n",
    "    'science_score': 'mean',\n",
    "    'attendance': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\nAverage scores by age:\")\n",
    "print(age_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2:** Handle missing data (we'll artificially create some):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce some missing values\n",
    "students_with_missing = students_df.copy()\n",
    "students_with_missing.loc[2, 'math_score'] = np.nan\n",
    "students_with_missing.loc[5, 'science_score'] = np.nan\n",
    "students_with_missing.loc[7, 'attendance'] = np.nan\n",
    "\n",
    "print(\"DataFrame with missing values:\")\n",
    "print(students_with_missing)\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(students_with_missing.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with column mean\n",
    "students_filled = students_with_missing.fillna(students_with_missing.mean())\n",
    "\n",
    "print(\"\\nAfter filling with mean:\")\n",
    "print(students_filled)\n",
    "\n",
    "# Alternatively, drop rows with missing values\n",
    "students_dropped = students_with_missing.dropna()\n",
    "print(f\"\\nRows after dropping NaN: {len(students_dropped)} (was {len(students_with_missing)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3:** Merge weather data with city information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create city information\n",
    "city_info = pd.DataFrame({\n",
    "    'city': ['Limerick', 'Galway', 'Dublin', 'Cork', 'Belfast'],\n",
    "    'population': [94192, 79934, 554554, 208669, 343542],\n",
    "    'province': ['Munster', 'Connacht', 'Leinster', 'Munster', 'Ulster']\n",
    "})\n",
    "\n",
    "# Merge dataframes\n",
    "weather_merged = pd.merge(weather_df, city_info, on='city')\n",
    "\n",
    "print(\"Merged weather data:\")\n",
    "print(weather_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Quick Exercise\n",
    "\n",
    "**Your turn!** Complete the following tasks:\n",
    "\n",
    "1. Calculate the temperature-to-humidity ratio for each city\n",
    "2. Find the city with the highest rainfall\n",
    "3. Create a new column categorising cities as 'Windy' (wind_speed > 15) or 'Calm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise solution space\n",
    "# 1. Temperature-to-humidity ratio\n",
    "\n",
    "\n",
    "# 2. City with highest rainfall\n",
    "\n",
    "\n",
    "# 3. Wind category\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Exercises\n",
    "\n",
    "people.csv and devices.json were given to you on Moodle\n",
    "\n",
    "Load both of these files using pandas and investigate the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Visualisation with Matplotlib\n",
    "\n",
    "Matplotlib is the foundational plotting library in Python. Let's explore various plot types:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Basic Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line plot - Student scores\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(students_df['name'], students_df['math_score'], \n",
    "         marker='o', label='Maths', linewidth=2)\n",
    "plt.plot(students_df['name'], students_df['science_score'], \n",
    "         marker='s', label='Science', linewidth=2)\n",
    "plt.xlabel('Student')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Student Scores Comparison')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart - Weather comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Temperature bar chart\n",
    "axes[0].bar(weather_merged['city'], weather_merged['temperature'], \n",
    "            color='skyblue', edgecolor='navy')\n",
    "axes[0].set_ylabel('Temperature (°C)')\n",
    "axes[0].set_title('Temperature by City')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Rainfall bar chart\n",
    "axes[1].bar(weather_merged['city'], weather_merged['rainfall_mm'], \n",
    "            color='steelblue', edgecolor='darkblue')\n",
    "axes[1].set_ylabel('Rainfall (mm)')\n",
    "axes[1].set_title('Rainfall by City')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot with trend line\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(students_df['attendance'], students_df['average_score'], \n",
    "            s=100, alpha=0.6, c=students_df['age'], cmap='viridis')\n",
    "plt.colorbar(label='Age')\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(students_df['attendance'], students_df['average_score'], 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(students_df['attendance'], p(students_df['attendance']), \n",
    "         \"r--\", alpha=0.8, label='Trend')\n",
    "\n",
    "plt.xlabel('Attendance (%)')\n",
    "plt.ylabel('Average Score')\n",
    "plt.title('Attendance vs Performance')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram - Score distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].hist(students_df['math_score'], bins=5, \n",
    "             color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Maths Score')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Maths Scores')\n",
    "\n",
    "axes[1].hist(students_df['science_score'], bins=5, \n",
    "             color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Science Score')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Distribution of Science Scores')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Subplots and Multiple Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dashboard-style visualisation\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Define grid\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Plot 1: Score comparison (spans 2 columns)\n",
    "ax1 = fig.add_subplot(gs[0, :2])\n",
    "x = np.arange(len(students_df))\n",
    "width = 0.35\n",
    "ax1.bar(x - width/2, students_df['math_score'], width, label='Maths', alpha=0.8)\n",
    "ax1.bar(x + width/2, students_df['science_score'], width, label='Science', alpha=0.8)\n",
    "ax1.set_xlabel('Student Index')\n",
    "ax1.set_ylabel('Scores')\n",
    "ax1.set_title('Score Comparison by Student')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Age distribution\n",
    "ax2 = fig.add_subplot(gs[0, 2])\n",
    "age_counts = students_df['age'].value_counts().sort_index()\n",
    "ax2.pie(age_counts.values, labels=age_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "ax2.set_title('Age Distribution')\n",
    "\n",
    "# Plot 3: Attendance box plot\n",
    "ax3 = fig.add_subplot(gs[1, :])\n",
    "ax3.boxplot([students_df['attendance'], students_df['math_score'], \n",
    "             students_df['science_score']], \n",
    "            labels=['Attendance', 'Maths', 'Science'])\n",
    "ax3.set_ylabel('Value')\n",
    "ax3.set_title('Distribution Comparison')\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 4: Weather scatter\n",
    "ax4 = fig.add_subplot(gs[2, :2])\n",
    "scatter = ax4.scatter(weather_merged['temperature'], weather_merged['humidity'], \n",
    "                     s=weather_merged['rainfall_mm']*100, \n",
    "                     c=weather_merged['wind_speed'], \n",
    "                     cmap='coolwarm', alpha=0.6, edgecolors='black')\n",
    "for i, city in enumerate(weather_merged['city']):\n",
    "    ax4.annotate(city, (weather_merged['temperature'].iloc[i], \n",
    "                        weather_merged['humidity'].iloc[i]))\n",
    "ax4.set_xlabel('Temperature (°C)')\n",
    "ax4.set_ylabel('Humidity (%)')\n",
    "ax4.set_title('Weather Patterns (size=rainfall, colour=wind speed)')\n",
    "plt.colorbar(scatter, ax=ax4, label='Wind Speed (km/h)')\n",
    "\n",
    "# Plot 5: Summary statistics\n",
    "ax5 = fig.add_subplot(gs[2, 2])\n",
    "ax5.axis('off')\n",
    "summary_text = f\"\"\"Summary Statistics:\n",
    "==================\n",
    "Students: {len(students_df)}\n",
    "Avg Maths: {students_df['math_score'].mean():.1f}\n",
    "Avg Science: {students_df['science_score'].mean():.1f}\n",
    "Avg Attendance: {students_df['attendance'].mean():.1f}%\n",
    "\n",
    "Cities: {len(weather_merged)}\n",
    "Avg Temp: {weather_merged['temperature'].mean():.1f}°C\n",
    "Avg Humidity: {weather_merged['humidity'].mean():.1f}%\n",
    "\"\"\"\n",
    "ax5.text(0.1, 0.5, summary_text, fontsize=10, family='monospace',\n",
    "         verticalalignment='center')\n",
    "\n",
    "plt.suptitle('Student Performance & Weather Dashboard', fontsize=16, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Working with Images\n",
    "\n",
    "Images are simply arrays of numbers! Let's explore how to work with them:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Create a simple RGB image using numpy\n",
    "# Red gradient\n",
    "red_image = np.zeros((200, 200, 3), dtype=np.uint8)\n",
    "for i in range(200):\n",
    "    red_image[:, i] = [i, 0, 0]  # RGB format\n",
    "\n",
    "# Blue gradient\n",
    "blue_image = np.zeros((200, 200, 3), dtype=np.uint8)\n",
    "for i in range(200):\n",
    "    blue_image[i, :] = [0, 0, i]\n",
    "\n",
    "# Save using PIL\n",
    "Image.fromarray(red_image).save('red_gradient.png')\n",
    "Image.fromarray(blue_image).save('blue_gradient.png')\n",
    "\n",
    "print(\"Created sample images: red_gradient.png and blue_gradient.png\")\n",
    "print(f\"Red image shape: {red_image.shape}\")\n",
    "print(f\"Data type: {red_image.dtype}\")\n",
    "print(f\"Value range: [{red_image.min()}, {red_image.max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Loading and Displaying Images\n",
    "\n",
    "**Important Note:** PIL and OpenCV handle colours differently!\n",
    "- **PIL/Matplotlib**: RGB (Red, Green, Blue)\n",
    "- **OpenCV**: BGR (Blue, Green, Red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image with PIL\n",
    "pil_image = Image.open('red_gradient.png')\n",
    "pil_array = np.array(pil_image)\n",
    "\n",
    "# Load same image with OpenCV\n",
    "cv_image = cv2.imread('red_gradient.png')\n",
    "\n",
    "# Compare\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(pil_array)\n",
    "axes[0].set_title('PIL (RGB) - Correct')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv_image)\n",
    "axes[1].set_title('OpenCV (BGR) displayed as RGB - Wrong!')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Convert BGR to RGB for correct display\n",
    "cv_image_rgb = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)\n",
    "axes[2].imshow(cv_image_rgb)\n",
    "axes[2].set_title('OpenCV converted to RGB - Correct')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice how the middle image looks wrong!\")\n",
    "print(\"Always convert OpenCV images: cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise, fix the colour space\n",
    "\n",
    "Now try with the image 353.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 353.jpg using OpenCV\n",
    "# Display it correctly using matplotlib\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Image as NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine image properties\n",
    "print(\"Image properties:\")\n",
    "print(f\"Shape: {pil_array.shape}\")  # (height, width, channels)\n",
    "print(f\"Data type: {pil_array.dtype}\")\n",
    "print(f\"Number of pixels: {pil_array.shape[0] * pil_array.shape[1]}\")\n",
    "print(f\"Total elements: {pil_array.size}\")\n",
    "\n",
    "# Access individual pixels\n",
    "print(f\"\\nTop-left pixel (RGB): {pil_array[0, 0]}\")\n",
    "print(f\"Top-right pixel (RGB): {pil_array[0, -1]}\")\n",
    "\n",
    "# Access colour channels\n",
    "print(f\"\\nRed channel shape: {pil_array[:, :, 0].shape}\")\n",
    "print(f\"Green channel shape: {pil_array[:, :, 1].shape}\")\n",
    "print(f\"Blue channel shape: {pil_array[:, :, 2].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise individual colour channels\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Original image\n",
    "axes[0, 0].imshow(pil_array)\n",
    "axes[0, 0].set_title('Original Image')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Red channel\n",
    "axes[0, 1].imshow(pil_array[:, :, 0], cmap='Reds')\n",
    "axes[0, 1].set_title('Red Channel')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Green channel\n",
    "axes[0, 2].imshow(pil_array[:, :, 1], cmap='Greens')\n",
    "axes[0, 2].set_title('Green Channel')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Blue channel\n",
    "axes[0, 3].imshow(pil_array[:, :, 2], cmap='Blues')\n",
    "axes[0, 3].set_title('Blue Channel')\n",
    "axes[0, 3].axis('off')\n",
    "\n",
    "# Do the same for blue gradient\n",
    "blue_array = np.array(Image.open('blue_gradient.png'))\n",
    "\n",
    "axes[1, 0].imshow(blue_array)\n",
    "axes[1, 0].set_title('Blue Gradient')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(blue_array[:, :, 0], cmap='Reds')\n",
    "axes[1, 1].set_title('Red Channel')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(blue_array[:, :, 1], cmap='Greens')\n",
    "axes[1, 2].set_title('Green Channel')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "axes[1, 3].imshow(blue_array[:, :, 2], cmap='Blues')\n",
    "axes[1, 3].set_title('Blue Channel')\n",
    "axes[1, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Pixel exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Access and print the pixel values at position (100, 100) in red_gradient.png\n",
    "# 2. What do you expect the RGB values to be? Check if you're right!\n",
    "# 3. Extract just the red channel and find its maximum value\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Channel Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new image where:\n",
    "# - Red channel comes from red_gradient.png\n",
    "# - Blue channel comes from blue_gradient.png\n",
    "# - Green channel is all zeros\n",
    "# Display the result - what colour do you expect?\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Normalisation: Converting from [0, 255] to [0, 1]\n",
    "\n",
    "Most machine learning models expect pixel values in [0, 1] rather than [0, 255]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original image (0-255)\n",
    "img_255 = np.array(Image.open('red_gradient.png'))\n",
    "print(\"Original range:\")\n",
    "print(f\"Min: {img_255.min()}, Max: {img_255.max()}, Dtype: {img_255.dtype}\")\n",
    "\n",
    "# Method 1: Simple division\n",
    "img_01 = img_255 / 255.0\n",
    "print(\"\\nAfter dividing by 255:\")\n",
    "print(f\"Min: {img_01.min():.3f}, Max: {img_01.max():.3f}, Dtype: {img_01.dtype}\")\n",
    "\n",
    "# Method 2: Using sklearn (useful for other normalisations too)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Reshape for sklearn (it expects 2D)\n",
    "img_flat = img_255.reshape(-1, 3)\n",
    "scaler = MinMaxScaler()\n",
    "img_scaled_flat = scaler.fit_transform(img_flat)\n",
    "img_scaled = img_scaled_flat.reshape(img_255.shape)\n",
    "\n",
    "print(\"\\nUsing sklearn MinMaxScaler:\")\n",
    "print(f\"Min: {img_scaled.min():.3f}, Max: {img_scaled.max():.3f}\")\n",
    "\n",
    "# Display both\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(img_255)\n",
    "axes[0].set_title('Original [0, 255]')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(img_01)\n",
    "axes[1].set_title('Normalised [0, 1]')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNote: Both images look identical because matplotlib handles both ranges!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Image Manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a more interesting image\n",
    "height, width = 300, 300\n",
    "x, y = np.meshgrid(np.linspace(-2, 2, width), np.linspace(-2, 2, height))\n",
    "\n",
    "# Create RGB channels with different patterns\n",
    "r = (np.sin(x) * np.cos(y) + 1) / 2\n",
    "g = (np.sin(x * 2) + 1) / 2\n",
    "b = (np.cos(y * 2) + 1) / 2\n",
    "\n",
    "pattern_img = np.dstack([r, g, b])\n",
    "pattern_img = (pattern_img * 255).astype(np.uint8)\n",
    "\n",
    "# Save it\n",
    "Image.fromarray(pattern_img).save('pattern.png')\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(pattern_img)\n",
    "plt.title('Generated Pattern Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various transformations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Original\n",
    "axes[0, 0].imshow(pattern_img)\n",
    "axes[0, 0].set_title('Original')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Grayscale (using luminosity method)\n",
    "gray = 0.299 * pattern_img[:, :, 0] + \\\n",
    "       0.587 * pattern_img[:, :, 1] + \\\n",
    "       0.114 * pattern_img[:, :, 2]\n",
    "axes[0, 1].imshow(gray, cmap='gray')\n",
    "axes[0, 1].set_title('Greyscale')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Inverted\n",
    "inverted = 255 - pattern_img\n",
    "axes[0, 2].imshow(inverted)\n",
    "axes[0, 2].set_title('Inverted')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Brightened\n",
    "brightened = np.clip(pattern_img * 1.5, 0, 255).astype(np.uint8)\n",
    "axes[1, 0].imshow(brightened)\n",
    "axes[1, 0].set_title('Brightened')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "# Only red channel\n",
    "red_only = pattern_img.copy()\n",
    "red_only[:, :, 1] = 0  # Remove green\n",
    "red_only[:, :, 2] = 0  # Remove blue\n",
    "axes[1, 1].imshow(red_only)\n",
    "axes[1, 1].set_title('Red Channel Only')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "# Flipped\n",
    "flipped = np.fliplr(pattern_img)\n",
    "axes[1, 2].imshow(flipped)\n",
    "axes[1, 2].set_title('Flipped Horizontally')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Create Your Own Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pattern.png, create the following:\n",
    "# 1. A version that's rotated 90 degrees (hint: use np.rot90)\n",
    "# 2. A version with reduced brightness (multiply by 0.5)\n",
    "# 3. A version with only the green and blue channels (remove red)\n",
    "# 4. Display all three in a subplot\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Create A Filter Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple \"vintage\" filter for pattern.png:\n",
    "# 1. Convert to grayscale using the luminosity method\n",
    "# 2. Add a sepia tone by creating an RGB image where:\n",
    "#    R = gray * 1.2, G = gray * 1.0, B = gray * 0.8\n",
    "# 3. Reduce the overall brightness by 10%\n",
    "# 4. Display original, grayscale, and sepia versions\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Use the dog image\n",
    "\n",
    "Using 353.jpg, try the vintage filter and try rotating the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Introduction to Scikit-learn\n",
    "\n",
    "Scikit-learn is the primary machine learning library in Python. Let's get familiar with its workflow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 The Scikit-learn Workflow\n",
    "\n",
    "All scikit-learn models follow the same pattern:\n",
    "1. **Import** the model class\n",
    "2. **Instantiate** the model (possibly with hyperparameters)\n",
    "3. **Fit** the model to training data\n",
    "4. **Predict** on new data\n",
    "5. **Evaluate** the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"age\", \"grade\"]].values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(X_scaled)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "kmeans.fit(X_scaled)\n",
    "\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's predict science scores from maths scores\n",
    "X = students_df[['math_score', 'attendance']]  # Features (2D array)\n",
    "y = students_df['science_score']  # Target (1D array)\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Target vector shape:\", y.shape)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import (already done above)\n",
    "# 2. Instantiate\n",
    "model = LinearRegression()\n",
    "\n",
    "# 3. Fit\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 5. Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R² Score: {r2:.3f}\")\n",
    "\n",
    "# Show predictions vs actual\n",
    "comparison = pd.DataFrame({\n",
    "    'Actual': y_test.values,\n",
    "    'Predicted': y_pred.round(1),\n",
    "    'Difference': (y_test.values - y_pred).round(1)\n",
    "})\n",
    "print(\"\\nPredictions vs Actual:\")\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6, s=100)\n",
    "plt.plot([y_test.min(), y_test.max()], \n",
    "         [y_test.min(), y_test.max()], \n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual Science Score')\n",
    "plt.ylabel('Predicted Science Score')\n",
    "plt.title('Model Predictions vs Actual Values')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Model coefficients\n",
    "print(\"\\nModel Parameters:\")\n",
    "print(f\"Coefficients: {model.coef_}\")\n",
    "print(f\"Intercept: {model.intercept_:.2f}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"Science Score = {model.intercept_:.1f} + \" \n",
    "      f\"{model.coef_[0]:.2f} * Maths + {model.coef_[1]:.2f} * Attendance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Classification Example\n",
    "\n",
    "Let's create a simple classification task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create a binary classification task: High vs Low performer\n",
    "# High performer: average score > 85\n",
    "students_df['performance'] = (students_df['average_score'] > 85).astype(int)\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "print(students_df['performance'].value_counts())\n",
    "\n",
    "# Features and target\n",
    "X_class = students_df[['math_score', 'attendance']]\n",
    "y_class = students_df['performance']\n",
    "\n",
    "# Split\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_class, y_class, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train classifier\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf.fit(X_train_c, y_train_c)\n",
    "\n",
    "# Predict\n",
    "y_pred_c = clf.predict(X_test_c)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test_c, y_pred_c)\n",
    "print(f\"\\nAccuracy: {accuracy:.2%}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_c, y_pred_c, \n",
    "                          target_names=['Low Performer', 'High Performer']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Working with Image Data in Sklearn\n",
    "\n",
    "Let's use our images with sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load our pattern image\n",
    "img = np.array(Image.open('pattern.png'))\n",
    "\n",
    "# Reshape image to 2D array (pixels x channels)\n",
    "pixels = img.reshape(-1, 3)\n",
    "print(f\"Reshaped to: {pixels.shape}\")\n",
    "print(f\"Each row is one pixel's RGB values\")\n",
    "\n",
    "# Normalise to [0, 1]\n",
    "pixels_norm = pixels / 255.0\n",
    "\n",
    "# Use K-Means to find dominant colours\n",
    "n_colours = 5\n",
    "kmeans = KMeans(n_clusters=n_colours, random_state=42, n_init=10)\n",
    "kmeans.fit(pixels_norm)\n",
    "\n",
    "# Get the dominant colours\n",
    "colours = kmeans.cluster_centers_\n",
    "colour_counts = np.bincount(kmeans.labels_)\n",
    "\n",
    "# Sort by frequency\n",
    "sorted_indices = np.argsort(colour_counts)[::-1]\n",
    "colours_sorted = colours[sorted_indices]\n",
    "counts_sorted = colour_counts[sorted_indices]\n",
    "\n",
    "# Display dominant colours\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 6))\n",
    "\n",
    "# Original image\n",
    "axes[0].imshow(img)\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Dominant colours\n",
    "axes[1].barh(range(n_colours), counts_sorted, \n",
    "             color=[colours_sorted[i] for i in range(n_colours)])\n",
    "axes[1].set_yticks(range(n_colours))\n",
    "axes[1].set_yticklabels([f'Colour {i+1}' for i in range(n_colours)])\n",
    "axes[1].set_xlabel('Number of Pixels')\n",
    "axes[1].set_title('Dominant Colours in Image')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDominant colours (RGB in [0,1]):\")\n",
    "for i, (colour, count) in enumerate(zip(colours_sorted, counts_sorted)):\n",
    "    pct = count/pixels.shape[0]*100\n",
    "    print(f\"{i+1}. RGB: {colour} - {count:,} pixels ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Putting It All Together - Mini Challenge\n",
    "\n",
    "Now it's your turn! Complete the following challenges to test your understanding:\n",
    "\n",
    "### Challenge 1: Data Analysis\n",
    "1. Load the weather.json file\n",
    "2. Calculate the \"comfort index\" as: `comfort = temperature * (100 - humidity) / wind_speed`\n",
    "3. Find which city has the highest comfort index\n",
    "4. Create a visualisation showing comfort index by city\n",
    "\n",
    "### Challenge 2: Image Processing\n",
    "1. Load the pattern.png image\n",
    "2. Create a version with only blue and green channels (no red)\n",
    "3. Normalise it to [0, 1]\n",
    "4. Display the original and modified images side by side\n",
    "\n",
    "### Challenge 3: Sklearn Practice\n",
    "1. Using the students data, predict `attendance` from `math_score` and `science_score`\n",
    "2. Split the data 70/30 train/test\n",
    "3. Train a model and calculate the R² score\n",
    "4. Visualise predicted vs actual attendance\n",
    "\n",
    "**Starter code below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 1: Data Analysis\n",
    "# Your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 2: Image Processing  \n",
    "# Your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 3: Sklearn Practice\n",
    "# Your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary and Key Takeaways\n",
    "\n",
    "### Pandas\n",
    "- `pd.read_csv()` and `pd.read_json()` for loading data\n",
    "- `df.head()`, `df.describe()`, `df.info()` for exploration\n",
    "- `df.fillna()` and `df.dropna()` for handling missing data\n",
    "- `df.groupby()` for aggregations\n",
    "- `pd.merge()` for combining dataframes\n",
    "\n",
    "### Matplotlib\n",
    "- `plt.plot()` for line plots\n",
    "- `plt.bar()` for bar charts\n",
    "- `plt.scatter()` for scatter plots\n",
    "- `plt.hist()` for histograms\n",
    "- `plt.imshow()` for images\n",
    "- Always use `plt.tight_layout()` for better spacing\n",
    "\n",
    "### Images\n",
    "- Images are numpy arrays with shape (height, width, channels)\n",
    "- PIL uses RGB, OpenCV uses BGR\n",
    "- Normalise from [0, 255] to [0, 1] by dividing by 255\n",
    "- Use `cv2.cvtColor()` to convert colour spaces\n",
    "\n",
    "### Scikit-learn\n",
    "- All models follow: import → instantiate → fit → predict → evaluate\n",
    "- `train_test_split()` to split data\n",
    "- Different metrics for regression (MSE, R²) vs classification (accuracy, F1)\n",
    "- Models have `.fit()`, `.predict()`, and `.score()` methods\n",
    "\n",
    "---\n",
    "## Next Steps\n",
    "\n",
    "In the next lab, we'll start building actual machine learning models for regression tasks!\n",
    "\n",
    "**Resources:**\n",
    "- Pandas documentation: https://pandas.pydata.org/docs/\n",
    "- Matplotlib gallery: https://matplotlib.org/stable/gallery/\n",
    "- Scikit-learn tutorials: https://scikit-learn.org/stable/tutorial/\n",
    "- OpenCV tutorials: https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html\n",
    "\n",
    "**Optional Practice:**\n",
    "1. Try loading your own CSV files\n",
    "2. Create more complex visualisations\n",
    "3. Experiment with different sklearn models (see documentation)\n",
    "4. Process your own images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
